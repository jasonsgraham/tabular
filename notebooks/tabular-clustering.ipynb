{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Ensemble various Clustering methods\n","\n","We don't have information about the number of clusters so we can run multiple models with different parameters and then allow the models to vote.  The cluster assignment with the most votes is the one we will assign the data point to. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","sns.set_style('darkgrid')\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.decomposition import IncrementalPCA\n","from sklearn.mixture import GaussianMixture, BayesianGaussianMixture\n","from sklearn.preprocessing import StandardScaler, RobustScaler, PowerTransformer"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"../input/tabular-playground-series-jul-2022/data.csv\")\n","submission = pd.read_csv(\"../input/tabular-playground-series-jul-2022/sample_submission.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = df.drop(columns = \"id\")\n","cols = list(df.columns)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Drop features that do not help us with clustering\n","drop_feats = [f'f_0{i}' for i in range(7)]\n","drop_feats = drop_feats + [f'f_{i}' for i in range(14,22)]\n","data_crop = data.drop(drop_feats, axis=1)\n","data_crop"]},{"cell_type":"markdown","metadata":{},"source":["## Preprocessing\n","- Here we try out different preprocessing pipelines"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_scaled = RobustScaler().fit_transform(df)\n","X_scaled = PowerTransformer().fit_transform(X_scaled)\n","X_scaled = pd.DataFrame(X_scaled, columns = cols)"]},{"cell_type":"markdown","metadata":{},"source":["## Additional Hyperparameters\n","- We now define a set of hyperparameters that we are **not** going to search values for. \n","- We simply set them to be the same for all instances of our algorithm. "]},{"cell_type":"markdown","metadata":{},"source":["**Plotting the data before we start searching**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pca = PCA(random_state = 10, whiten = True)\n","X_pca = pca.fit_transform(X_scaled)\n","PCA_df = pd.DataFrame({\"PCA_1\" : X_pca[:,0], \"PCA_2\" : X_pca[:,1]})\n","\n","plt.figure(figsize=(14, 14))\n","sns.scatterplot(data = PCA_df, x = \"PCA_1\", y = \"PCA_2\", s=3, color='Red');"]},{"cell_type":"markdown","metadata":{},"source":["# Brute Force ðŸ”¥\n","## Searching for the optimal hyperparameters\n","- We now search the range of possible values to assign to our algorithm hyperparameters\n","- **Note:** The final one we use each time is names `preds_1`, this allows it to be used at the end of the notebook for submission."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["models = {}\n","\n","def ensemble_models(models):\n","    for m in models:\n","        print(m)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["SEED = 620\n","additional_hyperparams = dict(  \n","                              covariance_type = 'full', \n","                              random_state = SEED, \n","                              n_init = 5, \n","                              tol=.01\n","                             )"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gm = GaussianMixture(n_components=7, **additional_hyperparams)\n","gm_preds = gm.fit_predict(X_scaled)\n","\n","models['GaussianMixture'] = gm_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["bgm = BayesianGaussianMixture(n_components=7, **additional_hyperparams)\n","bgm_preds = bgm.fit_predict(X_scaled)\n","\n","models['BayesianGaussianMixture'] = bgm_preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ensemble_models(models)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["pca = PCA(n_components=2)\n","reduced_data = pca.fit_transform(X_scaled)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.DataFrame({\"x\" : reduced_data[:,0], \"y\" : reduced_data[:,1], \"clusters\" : gm_preds})\n","plt.figure(figsize=(20, 10))\n","sns.scatterplot(x=df[\"x\"], y=df[\"y\"], hue=df[\"clusters\"], palette=\"deep\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["df = pd.DataFrame({\"x\" : reduced_data[:,0], \"y\" : reduced_data[:,1], \"clusters\" : bgm_preds})\n","plt.figure(figsize=(20, 10))\n","sns.scatterplot(x=df[\"x\"], y=df[\"y\"], hue=df[\"clusters\"], palette=\"deep\")"]},{"cell_type":"markdown","metadata":{},"source":["# Submission"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission[\"Predicted\"] = preds"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["submission.to_csv('../output/submission.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.4 ('tab')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.4"},"vscode":{"interpreter":{"hash":"6f76f6c53d8d9d2a9a6e4336e07b1de2471cc1af17e1f74b8993bd4507bef802"}}},"nbformat":4,"nbformat_minor":4}
